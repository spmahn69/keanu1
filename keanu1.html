html

<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>텍스트 문서 보기</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            line-height: 1.6;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border: 1px solid #ccc;
            overflow: auto;
        }
    </style>
</head>
<body>
    <h1>keanu_1</h1>
    <pre id="textContent">
실습.1

iris 데이터를 이용한 AI분류 문제

붓꽃의 종류, 길이, 너비 등의 데이터를 이용하여 붓꽃(iris)의 종류를 분류하는 AI 모델 제작 문제입니다.

AI코딩 단계에 따라 주어지는 문제를 읽고 답안을 작성하세요.

데이터 : 분류(카테고리)
모델 : RandomForest, DeepLerning
주요 전처리 : 분석 Column 추가, label 전처리(카테고리 → 수치화)
주요 학습 내용 : 산점도, 히스토그램, 분류형 모델 생성(분류방법, input, output 처리, 손실함수 등)
iris.csv / iris(붓꽃) 데이터 컬럼 설명

sepal.length : 큰 꽃잎의 길이
sepal.width : 큰 꽃잎의 너비
petal.length : 작은 꽃잎의 길이
petal.width : 작은 꽃잎의 너비
variety : 클래스, target, label
Setosa, Versicolor, Virginica

Q1. Pandas를 pd로 alias하여 사용할 수 있도록 불러오는 코드를 작성하고 실행하시기 바랍니다.¶
import pandas as pd

Q2.Matplotlib의 pyplot을 plt로 alias하여 사용할 수 있도록 불러오는 코드를 작성하고 실행하시기 바랍니다

import matplotlib.pyplot as plt

Q3.iris.csv를 판다스 데이터 프레임으로 불러와서 iris에 선언하는 코드를 작성하고 실행하시기 바랍니다.¶

iris = pd.read_csv(aidu_framework.config.data_dir + '/iris.csv')

Q4. 데이터 프레임 iris의 처음 6개 행을 조회하는 코드를 작성하고 실행하시기 바랍니다.

iris.head(6)

Q5. 데이터 프레임 iris의 variety 컬럼을 바 플롯(bar plot)을 이용하여 시각화 하시기 바랍니다.

iris['variety'].value_counts().plot(kind='hist')
plt.show()

Q6. 데이터 프레임 iris의 sepal.length 컬럼을 히스토 그램을 이용하여 시각화 하시기 바랍니다.

plt.hist(iris['sepal.length'])
plt.show()

또는

iris['sepal.length'].plot(kind='hist')
plt.show()

Q7. 데이터 프레임 iris의 petal.width 컬럼을 히스토 그램을 이용하여 시각화 하시기 바랍니다.¶
다섯개 구간으로 나누어 시각화 하시오.

plt.hist(iris['petal.width'], bins=5)
plt.show()

또는

iris['petal.width'].plot(kind='hist', bins=5)
plt.show()

Q8. 데이터 프레임 iris의 sepal.width를 x축으로 petal.width를 y축으로 하는 산점도를 시각화 하시기 바랍니다.

plt.scatter(x=iris['sepal.width'],y=iris['petal.width'])
plt.show()

또는

iris.plot(kind='scatter',x='sepal.width',y='petal.width')
plt.show()

Q9. 데이터 프레임 iris의 sepal.length를 x축으로 petal.length를 y축으로 하는 산점도를 시각화 하시기 바랍니다.
class에 따라 다른색을 띄도록 시각화 하시오.

groups=iris.groupby('variety')

for name, group in groups :
    plt.scatter(x='sepal.length',y='petal.length', data=group, label=name)
plt.legend()
plt.show()

Q10. 다음 조건에 맞추어 데이터 프레임 iris에 새로운 컬럼 sepal_ratio 를 추가하시기 바랍니다.
sepal.length를 분자로 sepal..width를 분모로 하는 비율을 sepal_ratio로 정의한다.

iris['sepal_ratio']=iris['sepal.length']/iris['sepal.width']
iris

Q11. 다음 조건에 맞추어 데이터 프레임 iris에 새로운 컬럼 length_diff 를 추가하시기 바랍니다.
sepal.length와 petal.length의 차이의 크기를 length_diff로 정의한다.

iris['length_diff']=abs(iris['sepal.length']-iris['petal.length'])
iris

Q12. 데이터 프레임 iris의 컬럼 variety를 label encoding하시기 바랍니다.

from sklearn.preprocessing import LabelEncoder

lb=LabelEncoder()
iris['variety']=lb.fit_transform(iris['variety'])
iris

Q13. 데이터를 트레이닝셋 / 테스트셋으로 분할하시기 바랍니다.

y는 iris데이터 프레임의 'variety'컬럼이고 x는 그 나머지 컬럼이다.
train : test = 9 : 1
y의 클래스가 골고루 분할되도록 stratify하게 분할한다.
변수명 규칙은 다음과 같다.
x_train, y_train
x_test, y_test
random state, seed 등은 2021로 설정한다.

from sklearn.model_selection import train_test_split

x=iris.drop('variety', axis=1)     # x=iris.drop([‘variety’], axis=1)  뭐가 맞지?
y=iris['variety']
x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.1, random_state=2021, stratify=y)

Q15. Random Forest 모델들을 학습시키시기 바랍니다.

RandomForestClassifier 하이퍼파라미터 설정 : n_estimators=50, max_depth=13, random_state=30, min_samples_leaf=5
n_estimators 종합한 전체 트리의 가지수, max_depth : 각 Tree의 가장 깊은 높이, min_samples_leaf: 각 끝의 노드에는 최소 5개의 트레이닝 샘플이 있어야함
트레이닝 셋 (x_train, y_train)을 이용하여 학습시킨다.
Forest를 이루는 tree의 leaf안에는 최소한 5개의 트레이닝셋 샘플이 있어야 한다.
seed나 random_state는 2021로 고정한다.
 
from sklearn.ensemble import RandomForestClassifier

forest = RandomForestClassifier(n_estimators=50, max_depth=13, min_samples_leaf=5, random_state=2021)
forest.fit(x_train, y_train)
forest.score(x_test, y_test)

다음 문항을 풀기 전에 아래 코드를 실행하세요.

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras.layers import Input, Dense, BatchNormalization
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.callbacks import EarlyStopping

Q16. 아래 조건에 맞추어 뉴럴네트워크 모델을 학습시키시기 바랍니다

Tensorflow framework를 사용한다.
히든레이어는 아래와 같은 규칙에 맞추어 구성합니다.
2개의 fully connected layer를 사용할 것
Batchnormalization을 반드시 활용한다.
Early stopping을 이용하여, validation loss가 5번 이상 개선되지 않으면 학습을 중단 시키고, 가장 성능이 좋았을 때의 가중치를 복구한다.
학습과정의 로그(loss, accuracy)를 history에 선언하여 남긴다.
y를 별도로 원핫인코딩 하지 않고 분류모델을 학습시킬 수 있도록 한다.(해당 형태의 경우 loss function은 sparse_categorical_crossentropy를 활용해야한다.)
epochs는 2000번을 지정한다.

keras.backend.clear_session()

model = Sequential()
model.add(Dense(36, activation='relu', input_shape=(6,)))
model.add(BatchNormalization())
model.add(Dense(36, activation='relu' ))
model.add(BatchNormalization())
model.add(Dense(12, activation='relu'))
model.add(Dense(3, activation='softmax'))
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, restore_best_weights=True)
history = model.fit(x_train, y_train, epochs=2000, batch_size=32,
                    verbose=1,validation_data=(x_test, y_test),callbacks=[es])

Q17. 다음 조건에 맞추어 뉴럴네트워크의 학습 로그를 시각화 하시기 바랍니다
필요한 라이브러리가 있다면 따로 불러온다.
epochs에 따른 accuracy의 변화를 시각화 한다.
train accuracy와 validation accuracy를 전부 시각화하고, 구별가능해야 한다.
그래프의 타이틀은 'Accuracy'로 표시한다..
x축에는 'epochs'라고 표시하고 y축에는 'accuracy'라고 표시한다.
 
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend(['train_acc', 'val_acc'])


[1번] Iris 이용

붓꽃의 종류, 길이, 너비 등의 데이터를 이용하여 붓꽃(iris)의 종류를 분류하는 AI 모델 제작 문제입니다.

AI코딩 단계에 따라 주어지는 문제를 읽고 답안을 작성하세요.

데이터 : 분류(카테고리)
모델 : RandomForest, DeepLerning
주요 전처리 : 분석 Column 추가, label 전처리(카테고리 → 수치화)
주요 학습 내용 : 산점도, 히스토그램, 분류형 모델 생성(분류방법, input, output 처리, 손실함수 등)
iris.csv / iris(붓꽃) 데이터 컬럼 설명

sepal.length : 큰 꽃잎의 길이
sepal.width : 큰 꽃잎의 너비
petal.length : 작은 꽃잎의 길이
petal.width : 작은 꽃잎의 너비
variety : 클래스, target, label
Setosa, Versicolor, Virginica
 

import pandas as pd

import matplotlib.pyplot as plt

iris = pd.read_csv(aidu_framework.config.data_dir + '/iris.csv')

Q4. 데이터 프레임 iris의 처음 6개 행을 조회하는 코드를 작성하고 실행하시기 바랍니다.

iris.head(6)

Q5. 데이터 프레임 iris의 variety 컬럼을 바 플롯(bar plot)을 이용하여 시각화 하시기 바랍니다.¶

iris['variety'].value_counts().plot(kind='bar')

plt.show()

Q6. 데이터 프레임 iris의 sepal.length 컬럼을 히스토 그램을 이용하여 시각화 하시기 바랍니

iris['sepal.length'].plot(kind='hist')

plt.show()

Q7. 데이터 프레임 iris의 petal.width 컬럼을 히스토 그램을 이용하여 시각화 하시기 바랍니다.

다섯개 구간으로 나누어 시각화 하시오.
iris['petal.width'].plot(kind='hist',bins=5)

plt.show()

Q8. 데이터 프레임 iris의 sepal.width를 x축으로 petal.width를 y축으로 하는 산점도를 시각화 하시기 바랍니다.

iris.plot(kind='scatter',x='sepal.width',y='petal.width')

plt.show()

Q9. 데이터 프레임 iris의 sepal.length를 x축으로 petal.length를 y축으로 하는 산점도를 시각화 하시기 바랍니다

class에 따라 다른색을 띄도록 시각화 하시오.
group=iris.groupby('variety')

group

for name, group in group :

    plt.scatter(x='sepal.length',y='petal.length',data=group, label=name)

   

plt.legend()

plt.show()

 

Q10. 다음 조건에 맞추어 데이터 프레임 iris에 새로운 컬럼 sepal_ratio 를 추가하시기 바랍니다.

sepal.length를 분자로 sepal.width를 분모로 하는 비율을 sepal_ratio로 정의한다

 

iris['sepal_ratio']=iris['sepal.length']/iris['sepal.width']

iris

Q11. 다음 조건에 맞추어 데이터 프레임 iris에 새로운 컬럼 length_diff 를 추가하시기 바랍니다.

sepal.length와 petal.length의 차이의 크기를 length_diff로 정의한다.
iris['length_diff'] = abs(iris['sepal.length'] - iris['petal.length'])

Q12. 데이터 프레임 iris의 컬럼 variety를 label encoding하시기 바랍니다.

# 여기에 답안코드를 작성하세요

from sklearn.preprocessing import LabelEncoder

lb = LabelEncoder()

iris['variety'] = lb.fit_transform(iris['variety'])

Q13. 데이터를 트레이닝셋 / 테스트셋으로 분할하시기 바랍니다.

y는 iris데이터 프레임의 'variety'컬럼이고 x는 그 나머지 컬럼이다.
train : test = 9 : 1
y의 클래스가 골고루 분할되도록 stratify하게 분할한다.
변수명 규칙은 다음과 같다.
x_train, y_train
x_test, y_test
random state, seed 등은 2021로 설정한다.
x = iris.drop(['variety'], axis=1)

y = iris['variety']

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2021, stratify = y)

Q15. Random Forest 모델들을 학습시키시기 바랍니다.

RandomForestClassifier 하이퍼파라미터 설정 : n_estimators=50, max_depth=13, random_state=30, min_samples_leaf=5
n_estimators 종합한 전체 트리의 가지수, max_depth : 각 Tree의 가장 깊은 높이, min_samples_leaf: 각 끝의 노드에는 최소 5개의 트레이닝 샘플이 있어야함
트레이닝 셋 (x_train, y_train)을 이용하여 학습시킨다.
Forest를 이루는 tree의 leaf안에는 최소한 5개의 트레이닝셋 샘플이 있어야 한다.
seed나 random_state는 2021로 고정한다.
 

from sklearn.ensemble import RandomForestClassifier

forest=RandomForestClassifier(n_estimators=50, max_depth=13, random_state=2021, min_samples_leaf=5)

forest.fit(x_train, y_train)

forest.score(x_test, y_test)

다음 문항을 풀기 전에 아래 코드를 실행하세요.

import tensorflow as tf

from tensorflow import keras

from tensorflow.keras.layers import Input, Dense, BatchNormalization

from tensorflow.keras.models import Sequential, Model

from tensorflow.keras.callbacks import EarlyStopping

Q16. 아래 조건에 맞추어 뉴럴네트워크 모델을 학습시키시기 바랍니다.

Tensorflow framework를 사용한다.
히든레이어는 아래와 같은 규칙에 맞추어 구성합니다.
2개의 fully connected layer를 사용할 것
Batchnormalization을 반드시 활용한다.
Early stopping을 이용하여, validation loss가 5번 이상 개선되지 않으면 학습을 중단 시키고, 가장 성능이 좋았을 때의 가중치를 복구한다.
학습과정의 로그(loss, accuracy)를 history에 선언하여 남긴다.
y를 별도로 원핫인코딩 하지 않고 분류모델을 학습시킬 수 있도록 한다.(해당 형태의 경우 loss function은 sparse_categorical_crossentropy를 활용해야한다.)
epochs는 2000번을 지정한다.
keras.backend.clear_session()

model=Sequential()

 

model.add(Dense(36, activation='relu',input_shape=(6,)))

model.add(BatchNormalization())

model.add(Dense(36, activation='relu'))

model.add(BatchNormalization())

model.add(Dense(12, activation='relu'))

model.add(Dense(3, activation='softmax'))

 

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

es=EarlyStopping(monitor='val_loss',min_delta=0, patience=5, verbose=1, restore_best_weights=True)

history=model.fit(x_train, y_train, epochs=2000, batch_size=32,  verbose=1, validation_data=(x_test, y_test), callbacks=[es])

Q17. 다음 조건에 맞추어 뉴럴네트워크의 학습 로그를 시각화 하시기 바랍니다.¶

필요한 라이브러리가 있다면 따로 불러온다.
epochs에 따른 accuracy의 변화를 시각화 한다.
train accuracy와 validation accuracy를 전부 시각화하고, 구별가능해야 한다.
그래프의 타이틀은 'Accuracy'로 표시한다..
x축에는 'epochs'라고 표시하고 y축에는 'accuracy'라고 표시한다.
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])

plt.plot(history.history['val_accuracy'])

plt.title('Accuracy')

plt.xlabel('epochs')

plt.ylabel('accuracy')

plt.legend(['train_acc', 'val_acc'])

plt.show()

 

[2번] ade_sales 이용

레몬/오렌지 에이드 판매량, 날짜, 위치 등의 데이터를 이용하여 판매량을 예측하는 AI 문제 입니다.

AI코딩 단계에 따라 주어지는 문제를 읽고 답안을 작성하세요.

데이터 : 수치형(회귀)
모델 : RandomForest, DeepLearning
주요 전처리 : 분석 Column 추가, 데이터 형변환, 공백 처리, label 전처리(카테고리 → 수치화)
주요 학습 내용 : 산점도, 회귀형 모델 생성(회귀형 모델 ㅡ특성, input, output 처리, 손실함수 등)
ade_sales.csv / 에이드 판매 데이터 컬럼 설명

Date : 날짜, 2016년 7월 1일 ~ 31일
Location : 판매 장소, Park or Beach
Lemon : 레몬 에이드 판매량
Orange : 오렌지 에이드 판매량
Temperature : 기온
Leaflets : 손님에게 나누어준 전단지 수
price : 에이드 판매 가격 (단위 : 원)
import pandas as pd

import matplotlib.pyplot as plt

ade = pd.read_csv(aidu_framework.config.data_dir + '/ade_sales.csv', encoding='cp949')

Q4. 데이터 프레임 ade의 마지막 10개 행을 조회하는 코드를 작성하고 실행하시기 바랍니다.

ade.tail(10)

Q5. 데이터 프레임 ade는 총 몇개의 row와 column을 가지고 있는지 출력하는 코드를 작성하고 실행하시기 바랍니다.

print(ade.shape)

Q6. 데이터 프레임 ade에서 중복된 열을 찾아 제거하는 코드를 작성하고 실행하시기 바랍니다.

ade.drop_duplicates(inplace=True, ignore_index=True)

ade

Q7. 데이터 프레임 ade에서 컬럼 Date의 데이터 타입을 날짜타입으로 올바르게 변환하는 코드를 작성하고 실행하시기 바랍니다.

ade['Date']=pd.to_datetime(ade['Date'])

ade

Q8. 데이터 프레임 ade에서 빈칸의 위치를 찾는 코드를 작성하고 실행하시기 바랍니다.

print('열 확인\n',ade.isnull().any())

print('열 확인\n',ade[ade.isnull().any(axis=1)].index)

Q9. 8번 문항(Q8)에서 확인된 빈칸을, 빈칸으로 부터 과거 4일사이의 값들의 평균을 계산하고 반올림하여 메우는(Imputing) 코드를 작성하고 실행하시기 바랍니다.¶

import numpy as np

ade.loc[19, 'Leaflets'] = np.around( ade.loc[15:18, 'Leaflets'].mean() )

print(ade.loc[19, 'Leaflets'])

Q10. 다음 조건에 맞추어 데이터 프레임 ade안에 day 컬럼을 추가하시기 바랍니다.¶

date 컬럼을 이용하여 요일을 만드시오.
요일은 dt.weekday를 활용해서 진행하시면 되며, 해당 진행시 integer로 encoding 됩니다.
ade['day'] = ade['Date'].dt.weekday # 월요일이 0이다.

ade

Q11. 다음 조건에 맞추어 데이터 프레임 ade안에 wdwe 컬럼을 추가하시기 바랍니다.¶

ade['wdwe'] = 1

ade.loc[ ade['day'].isin([5,6]) , 'wdwe'] = 0

print(ade.wdwe)

Q12. 데이터 프레임 ade의 Leaflets 컬럼을 x축으로 Lemon 컬럼을 y축으로하는 산점도를 시각화 하시기 바랍니다.

타이틀이 Lemon ~ Leaflets 이어야 한다.
ade.plot(kind='scatter', x='Lemon', y='Leaflets')

plt.title('Lemon ~ Leaflets')

plt.show()

ade.corr()

Q13. 데이터 프레임 ade안에 다음 조건에 맞추어 effect_leaflets 컬럼을 추가하시기 바랍니다.¶

레몬에이드와 오렌지에이드의 판매량 합계를 전단지 수로 나눈 값을 effect_leaflets로 정의한다.
ade['effect_leaflets'] = (ade['Lemon'] + ade['Orange']) / ade['Leaflets']

Q14. 데이터를 트레이닝셋 / 테스트셋으로 분할하시기 바랍니다.¶

y는 데이터 프레임의 'Lemon'과 'Orange'컬럼이다.
x는 'Temperature', 'Leaflets', 'price','effect_leaflets', 'wdwe'만 사용한다.
train : test = 9 : 1
Location의 Park와 Beach가 골고루 분배되도록 stratify하게 분할한다.
변수명 규칙은 다음과 같다.
x_train, y_train
x_test, y_test
random state, seed 등은 2021로 설정한다.
x = ade[['Temperature', 'Leaflets', 'price','effect_leaflets','wdwe']]

y = ade[['Lemon']]

 

from sklearn.model_selection import train_test_split

 

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2021, stratify = ade['Location'])

Q15. 트레이닝 데이터를 트레이닝셋 / 벨리데이션셋으로 분할하시기 바랍니다.

x_train, y_train을 이용한다.
train : validation = 8 : 2
변수명 규칙은 다음과 같다.
x_train, y_train
x_valid, y_valid
random state, seed 등은 2021로 설정한다.
from sklearn.model_selection import train_test_split

x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=2021)

Q16. 다중회귀 선형분석 모델들을 학습시키시기 바랍니다.¶

트레이닝 셋 (x_train, y_train['Lemon'])을 이용하여 학습시킨다.
from sklearn.linear_model import LinearRegression

line_fitter = LinearRegression()
line_fitter.fit(x_train, y_train)

Q17. linear Regression의 성능을 mean absolute error 성능 지표를 통해 확인하시기 바랍니다.

y_pred=line_fitter.predict(x_test)
from sklearn.metrics import mean_absolute_error as MAE
mae = MAE(y_test, y_pred)
print(mae)

Q18. 예측데이터와 실제 데이터를 산점도를 통해서, 정확성에 대해 시각화하여 확인해본다.

scatter plot을 이용한다.
사전에 예측한 예측 값(y_pred)와 실제 y_test의 lemon 항목에 대해 산점도를 그려본다.
x축과 y축에 라벨을 붙여준다.

plt.figure(figsize=(6, 6))

plt.scatter(y_test['Lemon'], y_pred, alpha=0.6)
plt.xlabel("Actual lemon")
plt.ylabel("Predicted lemon")
plt.title("MULTIPLE LINEAR REGRESSION")
plt.legend()
plt.show()
print(mae)

다음 문항을 풀기 전에 아래 코드를 실행하세요.

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras.layers import Input, Dense, BatchNormalization
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.callbacks import EarlyStopping

Q19. 아래 조건에 맞추어 뉴럴네트워크 모델을 학습시키시기 바랍니다.

Tensorflow framework를 사용한다.
히든레이어는 아래와 같은 규칙에 맞추어 구성한다.
1개의 fully connected layer를 사용할 것, 노드는 인풋레이어 노드의 2배로 한다.
Batchnormalization을 반드시 활용한다.
output layer는 Lemon 에이드 판매량을 예측할 수 있도록 구성한다.
output layer의 예측값이 0미만의 값이 나올 수 없도록 activation을 지정한다.
Early stopping을 이용하여, validation loss가 100번 이상 개선되지 않으면 학습을 중단 시키고, 가장 성능이 좋았을 때의 가중치를 복구한다.
학습과정의 로그(loss)를 history에 선언하여 남긴다. loss function은 mse를 사용한다.(Mean Squared Error)
epochs는 2000번을 지정한다.

keras.backend.clear_session()

model = Sequential()

model.add(Dense(16, activation='relu', input_shape=(5,)))
model.add(BatchNormalization())
model.add(Dense(16, activation='relu'))
model.add(BatchNormalization())
model.add(Dense(8, activation='relu'))
model.add(BatchNormalization())
model.add(Dense(1, activation='relu'))

model.compile(optimizer='adam', loss='mse')
es = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, restore_best_weights=True)
history = model.fit(x_train, y_train, epochs=2000, batch_size=32,
                    verbose=1,validation_data=(x_valid, y_valid),callbacks=[es])

Q20. 다음 조건에 맞추어 뉴럴네트워크의 학습 로그를 시각화 하시기 바랍니다.

필요한 라이브러리가 있다면 따로 불러온다.
epochs에 따른 loss의 변화를 시각화 한다.
train loss와 validation loss를 전부 시각화하고, 구별가능해야 한다.
그래프의 타이틀은 'Loss'로 표시한다.
x축에는 'epochs'라고 표시하고 y축에는 'MSE'라고 표시한다.

import matplotlib.pyplot as plt

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('MSE')
plt.legend(['train_loss', 'val_loss'])
plt.show()

Q22. 다음 조건에 맞추어 뉴럴네트워크의 예측 결과의 loss 값을 출력하시기 바랍니다
test 데이터를 활용하여, test 셋 데이터에 대해 mse 값을 출력하시오

from sklearn.metrics import mean_squared_error as MSE
y_pred=model.predict(x_test)
mse = MSE(y_test, y_pred)
print(mse)
plt.show()




    </pre>
</body>
</html>













